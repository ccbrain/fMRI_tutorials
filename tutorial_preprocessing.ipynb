{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: FMRI preprocessing and simple analysis\n",
    "\n",
    "The purpose of this section is that you setup a complete fMRI analysis workflow yourself. So that in the end you are able to perform the analysis from A-Z, i.e. from preprocessing to group analysis. This section will cover the preprocessing part, and the section [Hands-on 2: Analysis](handson_analysis.ipynb) will handle the analysis part.\n",
    "\n",
    "We will use this opportunity to show you some nice additional interfaces/nodes that might not be relevant to your usual analysis. But it's always nice to know that they exist. And hopefully this will encourage you to investigate all other interfaces that Nipype can bring to the tip of your finger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Before we can start with anything we first need to download the data. \n",
    "\n",
    "We will use structural and functional data from a single right-handed subject.\n",
    "\n",
    "**Note:** This might take a while, as datalad needs to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Total:   0%|          | 0.00/33.3M [00:00<?, ?B/s]\n",
      "\r",
      "sub-07/ses- .. _T1w.nii.gz:   0%|          | 0.00/8.58M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   0%|          | 0.00/24.8M [00:00<?, ?B/s]\u001b[A\u001b[A\r",
      "Total:  26%|██▌       | 8.58M/33.3M [00:01<00:03, 8.16MB/s]\n",
      "\r",
      "sub-07/ses- .. _T1w.nii.gz: 100%|██████████| 8.58M/8.58M [00:00<00:00, 20.2MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  26%|██▌       | 8.58M/33.3M [00:01<00:03, 8.16MB/s]\n",
      "\r",
      "                                                                                \u001b[A\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   0%|          | 73.9k/24.8M [00:00<00:37, 650kB/s]\u001b[A\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   1%|          | 195k/24.8M [00:00<00:33, 734kB/s] \u001b[A\r",
      "Total (1 ok out of 2):  27%|██▋       | 8.95M/33.3M [00:01<00:07, 3.26MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   1%|▏         | 368k/24.8M [00:00<00:28, 866kB/s]\u001b[A\r",
      "Total (1 ok out of 2):  28%|██▊       | 9.17M/33.3M [00:01<00:08, 2.70MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   2%|▏         | 590k/24.8M [00:00<00:23, 1.04MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  28%|██▊       | 9.46M/33.3M [00:01<00:09, 2.63MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   4%|▎         | 879k/24.8M [00:00<00:19, 1.26MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  29%|██▉       | 9.81M/33.3M [00:01<00:08, 2.74MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   5%|▍         | 1.23M/24.8M [00:00<00:15, 1.52MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  31%|███       | 10.2M/33.3M [00:01<00:07, 2.98MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   7%|▋         | 1.66M/24.8M [00:00<00:12, 1.86MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  32%|███▏      | 10.8M/33.3M [00:01<00:06, 3.38MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:   9%|▉         | 2.23M/24.8M [00:00<00:09, 2.28MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  35%|███▍      | 11.5M/33.3M [00:02<00:05, 3.90MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  12%|█▏        | 2.92M/24.8M [00:01<00:07, 2.80MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  37%|███▋      | 12.3M/33.3M [00:02<00:04, 4.51MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  15%|█▌        | 3.74M/24.8M [00:01<00:06, 3.43MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  43%|████▎     | 14.2M/33.3M [00:02<00:03, 5.34MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  23%|██▎       | 5.64M/24.8M [00:01<00:04, 4.23MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  46%|████▋     | 15.5M/33.3M [00:02<00:02, 6.31MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  28%|██▊       | 6.90M/24.8M [00:01<00:03, 5.19MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  52%|█████▏    | 17.3M/33.3M [00:02<00:02, 7.68MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  35%|███▌      | 8.70M/24.8M [00:01<00:02, 6.49MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  58%|█████▊    | 19.4M/33.3M [00:02<00:01, 9.33MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  44%|████▍     | 10.9M/24.8M [00:01<00:01, 8.07MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  65%|██████▌   | 21.7M/33.3M [00:02<00:01, 11.3MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  53%|█████▎    | 13.2M/24.8M [00:01<00:01, 9.99MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  72%|███████▏  | 23.9M/33.3M [00:02<00:00, 12.9MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  62%|██████▏   | 15.3M/24.8M [00:01<00:00, 11.6MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  79%|███████▊  | 26.2M/33.3M [00:03<00:00, 12.2MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  71%|███████▏  | 17.6M/24.8M [00:02<00:00, 11.4MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  85%|████████▍ | 28.2M/33.3M [00:03<00:00, 13.8MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  79%|███████▉  | 19.6M/24.8M [00:02<00:00, 13.1MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  91%|█████████ | 30.2M/33.3M [00:03<00:00, 15.1MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  88%|████████▊ | 21.7M/24.8M [00:02<00:00, 14.5MB/s]\u001b[A\r",
      "Total (1 ok out of 2):  97%|█████████▋| 32.2M/33.3M [00:03<00:00, 16.0MB/s]\n",
      "\r",
      "sub-07/ses- .. bold.nii.gz:  95%|█████████▌| 23.6M/24.8M [00:02<00:00, 15.5MB/s]\u001b[A\r",
      "Total (2 ok out of 2): 100%|██████████| 33.3M/33.3M [00:03<00:00, 16.0MB/s]\n",
      "\r",
      "                                                                                \u001b[A\r",
      "                                                                           \r",
      "get(ok): /data/ds000114/sub-07/ses-test/anat/sub-07_ses-test_T1w.nii.gz (file) [from origin...]\n",
      "get(ok): /data/ds000114/sub-07/ses-test/func/sub-07_ses-test_task-fingerfootlips_bold.nii.gz (file) [from web...]\n",
      "action summary:\n",
      "  get (ok: 2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "datalad get -J 4 /data/ds000114/sub-07/ses-test/anat/sub-07_ses-test_T1w.nii.gz \\\n",
    "                /data/ds000114/sub-07/ses-test/func/*fingerfootlips*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "It's always best to have all relevant module imports at the beginning of your script. So let's import what we most certainly need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Node and Workflow object\n",
    "from nipype import Node, Workflow\n",
    "\n",
    "# Specify which SPM to use\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('/opt/spm12/spm12_mcr/spm/spm12')\n",
    "\n",
    "from nilearn import image as nli\n",
    "from nilearn.image.image import mean_img\n",
    "from nilearn.plotting import plot_epi, plot_anat\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "import nibabel as nb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot anatomical and functional data\n",
    "%matplotlib inline\n",
    "plot_anat('/data/ds000114/sub-02/ses-test/anat/sub-07_ses-test_T1w.nii.gz')\n",
    "plot_epi(mean_img('/data/ds000114/sub-07/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Workflow Structure\n",
    "\n",
    "For the preprocessing workflow, we use the following nodes:\n",
    "\n",
    "     1. Gunzip (Nipype)\n",
    "     2. Drop Dummy Scans (FSL)\n",
    "     3. Slice Time Correction (SPM)\n",
    "     4. Motion Correction (SPM)\n",
    "     5. Artifact Detection\n",
    "     6. Segmentation (SPM)\n",
    "     7. Coregistration (FSL)\n",
    "     8. Smoothing (FSL)\n",
    "     9. Apply Binary Mask (FSL)\n",
    "    10. Remove Linear Trends (Nipype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nodes and Workflow connections\n",
    "\n",
    "Let's create all the nodes that we need! Make sure to specify all relevant inputs and keep in mind which ones you later on need to connect in your pipeline.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "We recommend to create the workflow and establish all it's connections at a later place in your script. This helps to have everything nicely together. But for this hands-on example it makes sense to establish the connections between the nodes as we go.\n",
    "\n",
    "And for this, we first need to create a workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow here\n",
    "preproc = Workflow(name='work_preproc', base_dir='/output/')\n",
    "\n",
    "# Specify example input file\n",
    "func_file = '/data/ds000114/sub-07/ses-test/func/sub-07_ses-test_task-fingerfootlips_bold.nii.gz'\n",
    "\n",
    "# Initiate Gunzip node\n",
    "gunzip_func = Node(Gunzip(in_file=func_file), name='gunzip_func')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Dummy Scans\n",
    "\n",
    "The functional images of this dataset were recorded with 4 dummy scans at the beginning (see the [corresponding publication](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3641991/)). But those dummy scans were not yet taken out from the functional images.\n",
    "\n",
    "To better illustrate this, let's plot the time course of a random voxel of the just defined `func_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(nb.load(func_file).get_fdata()[32, 32, 15, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, we see that at the very beginning there are extreme values, which hint to the fact that steady state wasn't reached yet. Therefore, we want to exclude the dummy scans from the original data. This can be achieved with FSL's `ExtractROI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import ExtractROI\n",
    "extract = Node(ExtractROI(t_min=4, t_size=-1, output_type='NIFTI'),\n",
    "               name=\"extract\")\n",
    "\n",
    "# This ExtractROI node can now be connected to the gunzip_func node from above. To do this, we use the following command:\n",
    "preproc.connect([(gunzip_func, extract, [('out_file', 'in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice Time Correction\n",
    "\n",
    "Now to the next step. Let's us SPM's `SliceTiming` to correct for slice wise acquisition of the volumes. As a reminder, the tutorial dataset was recorded...\n",
    "- with a time repetition (TR) of 2.5 seconds\n",
    "- with 30 slices per volume\n",
    "- in an interleaved fashion, i.e. slice order is [1, 3, 5, 7, ..., 2, 4, 6, ..., 30]\n",
    "- with a time acquisition (TA) of 2.4167 seconds, i.e. `TR-(TR/num_slices)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.spm import SliceTiming\n",
    "slice_order = list(range(1, 31, 2)) + list(range(2, 31, 2))\n",
    "print(slice_order)\n",
    "\n",
    "# Initiate SliceTiming node here\n",
    "slicetime = Node(SliceTiming(num_slices=30,\n",
    "                             ref_slice=15,\n",
    "                             slice_order=slice_order,\n",
    "                             time_repetition=2.5,\n",
    "                             time_acquisition=2.5-(2.5/30)),\n",
    "                 name='slicetime')\n",
    "\n",
    "# Connect SliceTiming node to the other nodes here\n",
    "preproc.connect([(extract, slicetime, [('roi_file', 'in_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction\n",
    "\n",
    "To correct for motion in the scanner, we will be using FSL's `MCFLIRT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import MCFLIRT\n",
    "\n",
    "# Initate MCFLIRT node here\n",
    "mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                       save_plots=True),\n",
    "               name=\"mcflirt\")\n",
    "\n",
    "# Connect the MCFLIRT node to the rest of the workflow.\n",
    "preproc.connect([(slicetime, mcflirt, [('timecorrected_files', 'in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact Detection\n",
    "\n",
    "We will use the really cool and useful `ArtifactDetection` tool from Nipype to detect motion and intensity outliers in the functional images. The interface is initiated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "art = Node(ArtifactDetect(norm_threshold=2,\n",
    "                          zintensity_threshold=3,\n",
    "                          mask_type='spm_global',\n",
    "                          parameter_source='FSL',\n",
    "                          use_differences=[True, False],\n",
    "                          plot_type='svg'),\n",
    "           name=\"art\")\n",
    "\n",
    "preproc.connect([(mcflirt, art, [('out_file', 'realigned_files'),\n",
    "                                 ('par_file', 'realignment_parameters')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters above mean the following:\n",
    "- `norm_threshold` - Threshold to use to detect motion-related outliers when composite motion is being used\n",
    "- `zintensity_threshold` - Intensity Z-threshold use to detection images that deviate from the mean\n",
    "- `mask_type` - Type of mask that should be used to mask the functional data. *spm_global* uses an spm_global like calculation to determine the brain mask\n",
    "- `parameter_source` - Source of movement parameters\n",
    "- `use_differences` - If you want to use differences between successive motion (first element) and intensity parameter (second element) estimates in order to determine outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation of anatomical image\n",
    "\n",
    "Now let's work on the anatomical image. In particular, let's use SPM's `NewSegment` to create probability maps for the gray matter, white matter tissue and CSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Duplicate node name \"gunzip_anat\" found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-4a3b848f7651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgunzip_anat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGunzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manat_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gunzip_anat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgunzip_anat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'channel_files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mnewnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36m_check_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mthis_node_lineage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                         raise IOError(\n\u001b[0;32m--> 727\u001b[0;31m                             'Duplicate node name \"%s\" found.' % node.name)\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mnode_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Duplicate node name \"gunzip_anat\" found."
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.spm import NewSegment\n",
    "# Use the following tissue specification to get a GM and WM probability map\n",
    "tpm_img ='/opt/spm12-dev/spm12_mcr/spm/spm12/tpm/TPM.nii'\n",
    "tissue1 = ((tpm_img, 1), 1, (True,False), (False, False))\n",
    "tissue2 = ((tpm_img, 2), 1, (True,False), (False, False))\n",
    "tissue3 = ((tpm_img, 3), 2, (True,False), (False, False))\n",
    "tissue4 = ((tpm_img, 4), 3, (False,False), (False, False))\n",
    "tissue5 = ((tpm_img, 5), 4, (False,False), (False, False))\n",
    "tissue6 = ((tpm_img, 6), 2, (False,False), (False, False))\n",
    "tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n",
    "\n",
    "# Initate NewSegment node here\n",
    "segment = Node(NewSegment(tissues=tissues), name='segment')\n",
    "\n",
    "# Specify example input file\n",
    "anat_file = '/data/ds000114/sub-07/ses-test/anat/sub-07_ses-test_T1w.nii.gz'\n",
    "\n",
    "# Initiate Gunzip node\n",
    "gunzip_anat = Node(Gunzip(in_file=anat_file), name='gunzip_anat')\n",
    "\n",
    "preproc.connect([(gunzip_anat, segment, [('out_file', 'channel_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Coregistration Matrix\n",
    "\n",
    "As a next step we will make sure that the functional images are coregistered to the anatomical image. For this we will use FSL's `FLIRT` function. As we just created a white matter probability map, we can use this together with the Boundary-Based Registration (BBR) cost function to optimize the image coregistration. As some helpful notes...\n",
    "- use a degree of freedom of 6\n",
    "- specify the cost function as `bbr`\n",
    "- use the `schedule='/usr/share/fsl/5.0/etc/flirtsch/bbr.sch'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Duplicate node name \"coreg\" found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-7138124382ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m preproc.connect([(gunzip_anat, coreg, [('out_file', 'reference')]),\n\u001b[0;32m---> 11\u001b[0;31m                  \u001b[0;34m(\u001b[0m\u001b[0mmcflirt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean_img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                  ])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mnewnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36m_check_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mthis_node_lineage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                         raise IOError(\n\u001b[0;32m--> 727\u001b[0;31m                             'Duplicate node name \"%s\" found.' % node.name)\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mnode_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Duplicate node name \"coreg\" found."
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.fsl import FLIRT\n",
    "\n",
    "# Initate FLIRT node here\n",
    "coreg = Node(FLIRT(dof=6,\n",
    "                   cost='bbr',\n",
    "                   schedule='/usr/share/fsl/5.0/etc/flirtsch/bbr.sch',\n",
    "                   output_type='NIFTI'),\n",
    "             name=\"coreg\")\n",
    "\n",
    "preproc.connect([(gunzip_anat, coreg, [('out_file', 'reference')]),\n",
    "                 (mcflirt, coreg, [('mean_img', 'in_file')])\n",
    "                 ])\n",
    "\n",
    "\n",
    "from nipype.interfaces.fsl import Threshold\n",
    "\n",
    "# Threshold - Threshold WM probability image\n",
    "threshold_WM = Node(Threshold(thresh=0.5,\n",
    "                              args='-bin',\n",
    "                              output_type='NIFTI'),\n",
    "                name=\"threshold_WM\")\n",
    "\n",
    "# Select WM segmentation file from segmentation output\n",
    "def get_wm(files):\n",
    "    return files[1][0]\n",
    "\n",
    "# Connecting the segmentation node with the threshold node\n",
    "preproc.connect([(segment, threshold_WM, [(('native_class_images', get_wm),\n",
    "                                           'in_file')])])\n",
    "\n",
    "# Now we can just connect this Threshold node to the coregistration node from above.\n",
    "preproc.connect([(threshold_WM, coreg, [('out_file', 'wm_seg')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Coregistration Matrix to functional image\n",
    "\n",
    "Now that we know the coregistration matrix to correctly overlay the functional mean image on the subject specific anatomy, we need to apply to coregistration to the whole time series. This can be achieved with FSL's `FLIRT` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Duplicate node name \"coreg\" found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-92ea46091785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m preproc.connect([(mcflirt, applywarp, [('out_file', 'in_file')]),\n\u001b[1;32m      5\u001b[0m                  \u001b[0;34m(\u001b[0m\u001b[0mcoreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplywarp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_matrix_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_matrix_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  \u001b[0;34m(\u001b[0m\u001b[0mgunzip_anat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplywarp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                  ])\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mnewnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36m_check_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    725\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mthis_node_lineage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                         raise IOError(\n\u001b[0;32m--> 727\u001b[0;31m                             'Duplicate node name \"%s\" found.' % node.name)\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mnode_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Duplicate node name \"coreg\" found."
     ]
    }
   ],
   "source": [
    "# Specify the isometric voxel resolution you want after coregistration\n",
    "desired_voxel_iso = 4\n",
    "\n",
    "# Apply coregistration warp to functional images\n",
    "applywarp = Node(FLIRT(interp='spline',\n",
    "                       apply_isoxfm=desired_voxel_iso,\n",
    "                       output_type='NIFTI'),\n",
    "                 name=\"applywarp\")\n",
    "\n",
    "# Connecting the ApplyWarp node to all the other nodes\n",
    "preproc.connect([(mcflirt, applywarp, [('out_file', 'in_file')]),\n",
    "                 (coreg, applywarp, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (gunzip_anat, applywarp, [('out_file', 'reference')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "Next step is image smoothing. The most simple way to do this is to use FSL's or SPM's `Smooth` function. But for learning purposes, let's use FSL's `SUSAN` workflow as it is implemented in Nipype. Note that this time, we are importing a workflow instead of an interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'applywarp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-8ad352b7a71e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Connect Threshold node to coregistration node above here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplywarp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msusan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputnode.in_files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'applywarp' is not defined"
     ]
    }
   ],
   "source": [
    "from nipype.workflows.fmri.fsl.preprocess import create_susan_smooth\n",
    "\n",
    "# Initate SUSAN workflow here\n",
    "susan = create_susan_smooth(name='susan')\n",
    "susan.inputs.inputnode.fwhm = 4\n",
    "\n",
    "# Connect Threshold node to coregistration node above here\n",
    "preproc.connect([(applywarp, susan, [('out_file', 'inputnode.in_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Binary Mask\n",
    "\n",
    "There are many possible approaches on how you can mask your functional images. One of them is not at all, one is with a simple brain mask and one that only considers certain kind of brain tissue, e.g. gray matter.\n",
    "\n",
    "For the current example, we want to create a dilated gray matter mask. For this purpose we need to:\n",
    "1. Resample the gray matter probability map to the same resolution as the functional images\n",
    "2. Threshold this resampled probability map at a specific value\n",
    "3. Dilate this mask by some voxels to make the mask less conservative and more inclusive\n",
    "\n",
    "The first step can be done in many ways (eg. using freesurfer's `mri_convert`, `nibabel`) but in our case we will use FSL's `FLIRT`. The trick is to use the probability mask, as input file and reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import FLIRT\n",
    "\n",
    "# Initiate resample node\n",
    "resample = Node(FLIRT(apply_isoxfm=desired_voxel_iso,\n",
    "                      output_type='NIFTI'),\n",
    "                name=\"resample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second and third step can luckily be done with just one node. We can take almost the same `Threshold` node as above. We just need to add another additional argument: `-dilF` - which applies a maximum filtering of all voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import Threshold\n",
    "\n",
    "# Threshold - Threshold GM probability image\n",
    "mask_GM = Node(Threshold(thresh=0.5,\n",
    "                         args='-bin -dilF',\n",
    "                         output_type='NIFTI'),\n",
    "                name=\"mask_GM\")\n",
    "\n",
    "# Select GM segmentation file from segmentation output\n",
    "def get_gm(files):\n",
    "    return files[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can connect the resample and the gray matter mask node to the segmentation node and each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.connect([(segment, resample, [(('native_class_images', get_gm), 'in_file'),\n",
    "                                      (('native_class_images', get_gm), 'reference')\n",
    "                                      ]),\n",
    "                 (resample, mask_GM, [('out_file', 'in_file')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should do the trick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the binary mask\n",
    "\n",
    "Now we can connect this dilated gray matter mask to the susan node, as well as actually applying this to the resulting smoothed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect gray matter Mask node to the susan workflow here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(mask_GM, susan, [('out_file', 'inputnode.mask_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the mask to the smoothed functional images, we will use FSL's `ApplyMask` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import ApplyMask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** The susan workflow gives out a list of files, i.e. `[smoothed_func.nii]` instead of just the filename directly. If we would use a normal `Node` for `ApplyMask` this would lead to the following error:\n",
    "\n",
    "    TraitError: The 'in_file' trait of an ApplyMaskInput instance must be an existing file name, but a value of ['/output/work_preproc/susan/smooth/mapflow/_smooth0/asub-07_ses-test_task-fingerfootlips_bold_mcf_flirt_smooth.nii.gz'] <class 'list'> was specified.\n",
    "\n",
    "\n",
    "To prevent this we will be using a `MapNode` and specify the `in_file` as it's iterfield. Like this the node is capable to handle a list of inputs as it will know that it has to apply itself iteratively to the list of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import MapNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initate ApplyMask node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mask_func = MapNode(ApplyMask(output_type='NIFTI'),\n",
    "                    name=\"mask_func\", \n",
    "                    iterfield=[\"in_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect smoothed susan output file to ApplyMask node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(susan, mask_func, [('outputnode.smoothed_files', 'in_file')]),\n",
    "                 (mask_GM, mask_func, [('out_file', 'mask_file')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove linear trends in functional images\n",
    "\n",
    "Last but not least. Let's use Nipype's `TSNR` module to remove linear and quadratic trends in the functionally smoothed images. For this you only have to specify the `regress_poly` parameter in the node initiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.algorithms.confounds import TSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Initate TSNR node here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "detrend = Node(TSNR(regress_poly=2), name=\"detrend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect the detrend node to the other nodes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(mask_func, detrend, [('out_file', 'in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datainput with `SelectFiles` and `iterables` \n",
    "\n",
    "This is all nice and well. But so far we still had to specify the input values for `gunzip_anat` and `gunzip_func` ourselves. How can we scale this up to multiple subjects and/or multiple functional images and make the workflow take the input directly from the BIDS dataset?\n",
    "\n",
    "For this, we need [`SelectFiles`](../../../nipype_tutorial/notebooks/basic_data_input.ipynb#SelectFiles) and [`iterables`](../../../nipype_tutorial/notebooks/basic_iteration.ipynb)! It's rather simple, specify a template and fill-up the placeholder variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SelectFiles\n",
    "from nipype import SelectFiles\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-{subject_id}/ses-{ses_id}/anat/'\n",
    "                     'sub-{subject_id}_ses-test_T1w.nii.gz',\n",
    "             'func': 'sub-{subject_id}/ses-{ses_id}/func/'\n",
    "                     'sub-{subject_id}_ses-{ses_id}_task-{task_id}_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates,\n",
    "                      base_directory='/data/ds000114',\n",
    "                      sort_filelist=True),\n",
    "          name='selectfiles')\n",
    "sf.inputs.ses_id='test'\n",
    "sf.inputs.task_id='fingerfootlips'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify over which subjects the workflow should iterate. To test the workflow, let's still just look at subject 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['07']\n",
    "sf.iterables = [('subject_id', subject_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect SelectFiles node to the other nodes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(sf, gunzip_anat, [('anat', 'in_file')]),\n",
    "                 (sf, gunzip_func, [('func', 'in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the workflow\n",
    "\n",
    "Now that we're done. Let's look at the workflow that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename='/output/work_preproc/graph.png', width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Now we are ready to run the workflow! Be careful about the `n_procs` parameter if you run a workflow in `'MultiProc'` mode. `n_procs` specifies the number of jobs/cores your computer will use to run the workflow. If this number is too high your computer will try to execute too many things at once and will most likely crash.\n",
    "\n",
    "**Note**: If  you're using a Docker container and FLIRT fails to run without any good reason, you might need to change memory settings in the Docker preferences (6 GB should be enough for this workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect output\n",
    "\n",
    "What did we actually do? Let's look at all the data that was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree /output/work_preproc/ -I '*js|*json|*pklz|_report|*dot|*html|*txt|*.m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what did we do specifically? Well, let's investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction and Artifact Detection\n",
    "\n",
    "How much did the subject move in the scanner and where there any outliers in the functional images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the motion paramters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "par = np.loadtxt('/output/work_preproc/_subject_id_07/mcflirt/'\n",
    "                 'asub-07_ses-test_task-fingerfootlips_bold_roi_mcf.nii.gz.par')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "axes[0].set_ylabel('rotation (radians)')\n",
    "axes[0].plot(par[0:, :3])\n",
    "axes[1].plot(par[0:, 3:])\n",
    "axes[1].set_xlabel('time (TR)')\n",
    "axes[1].set_ylabel('translation (mm)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motion parameters seems to look ok. What about the detection of artifacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the artifact detection output\n",
    "from IPython.display import SVG\n",
    "SVG(filename='/output/work_preproc/_subject_id_07/art/'\n",
    "    'plot.asub-07_ses-test_task-fingerfootlips_bold_roi_mcf.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which volumes are problematic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = np.loadtxt('/output/work_preproc/_subject_id_07/art/'\n",
    "                      'art.asub-07_ses-test_task-fingerfootlips_bold_roi_mcf_outliers.txt')\n",
    "list(outliers.astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks and Probability maps\n",
    "\n",
    "Let's see what all the masks and probability maps look like. For this we will use `nilearn`'s `plot_anat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image as nli\n",
    "from nilearn.plotting import plot_stat_map\n",
    "%matplotlib inline\n",
    "output = '/output/work_preproc/_subject_id_07/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the tissue probability maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat = output + 'gunzip_anat/sub-07_ses-test_T1w.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(\n",
    "    output + 'segment/c1sub-07_ses-test_T1w.nii', title='GM prob. map',  cmap=plt.cm.magma,\n",
    "    threshold=0.5, bg_img=anat, display_mode='z', cut_coords=range(-35, 15, 10), dim=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(\n",
    "    output + 'segment/c2sub-07_ses-test_T1w.nii', title='WM prob. map', cmap=plt.cm.magma,\n",
    "    threshold=0.5, bg_img=anat, display_mode='z', cut_coords=range(-35, 15, 10), dim=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(\n",
    "    output + 'segment/c3sub-07_ses-test_T1w.nii', title='CSF prob. map', cmap=plt.cm.magma,\n",
    "    threshold=0.5, bg_img=anat, display_mode='z', cut_coords=range(-35, 15, 10), dim=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how does the gray matter mask look like that we used on the functional images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(\n",
    "    output + 'mask_GM/c1sub-07_ses-test_T1w_flirt_thresh.nii', title='dilated GM Mask', cmap=plt.cm.magma,\n",
    "    threshold=0.5, bg_img=anat, display_mode='z', cut_coords=range(-35, 15, 10), dim=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Image transformations\n",
    "\n",
    "Let's also investigate the transformation that we applied to the functional images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image as nli\n",
    "from nilearn.plotting import plot_epi\n",
    "%matplotlib inline\n",
    "output = '/output/work_preproc/_subject_id_07/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epi(output + 'mcflirt/asub-07_ses-test_task-fingerfootlips_bold_roi_mcf.nii.gz_mean_reg.nii.gz',\n",
    "         title='Motion Corrected mean image', display_mode='z', cut_coords=range(-40, 21, 15),\n",
    "         cmap=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = nli.mean_img(output + 'applywarp/asub-07_ses-test_task-fingerfootlips_bold_roi_mcf_flirt.nii')\n",
    "plot_epi(mean, title='Coregistred mean image', display_mode='z', cut_coords=range(-40, 21, 15),\n",
    "         cmap=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = nli.mean_img('/output/work_preproc/susan/_subject_id_07/smooth/mapflow/_smooth0/'\n",
    "                    'asub-07_ses-test_task-fingerfootlips_bold_roi_mcf_flirt_smooth.nii.gz')\n",
    "plot_epi(mean, title='Smoothed mean image', display_mode='z', cut_coords=range(-40, 21, 15),\n",
    "         cmap=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = nli.mean_img(output + 'mask_func/mapflow/_mask_func0/'\n",
    "                    'asub-07_ses-test_task-fingerfootlips_bold_roi_mcf_flirt_smooth_masked.nii')\n",
    "plot_epi(mean, title='Masked mean image', display_mode='z', cut_coords=range(-40, 21, 15),\n",
    "         cmap=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epi(output + 'detrend/mean.nii.gz', title='Detrended mean image', display_mode='z',\n",
    "         cut_coords=range(-40, 21, 15), cmap=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all nice and beautiful, but what did smoothing and detrending actually do to the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "%matplotlib inline\n",
    "output = '/output/work_preproc/_subject_id_07/'\n",
    "\n",
    "# Load the relevant datasets\n",
    "mc = nb.load(output + 'applywarp/asub-07_ses-test_task-fingerfootlips_bold_roi_mcf_flirt.nii')\n",
    "smooth = nb.load('/output/work_preproc/susan/_subject_id_07/smooth/mapflow/'\n",
    "                 '_smooth0/asub-07_ses-test_task-fingerfootlips_bold_roi_mcf_flirt_smooth.nii.gz')\n",
    "detrended_data = nb.load(output + 'detrend/detrend.nii.gz')\n",
    "\n",
    "# Plot a representative voxel\n",
    "x, y, z = 32, 34, 43\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.plot(mc.get_data()[x, y, z, :])\n",
    "plt.plot(smooth.get_data()[x, y, z, :])\n",
    "plt.plot(detrended_data.get_data()[x, y, z, :])\n",
    "plt.legend(['motion corrected', 'smoothed', 'detrended']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data output with `DataSink`\n",
    "\n",
    "The results look fine, but we don't need all those temporary files. So let's use Datasink to keep only those files that we actually need for the 1st and 2nd level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink\n",
    "\n",
    "# Initiate the datasink node\n",
    "output_folder = 'datasink_handson'\n",
    "datasink = Node(DataSink(base_directory='/output/',\n",
    "                         container=output_folder),\n",
    "                name=\"datasink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step is to specify all the output that we want to keep in our output folder `output`. Make sure to keep:\n",
    "- from the artifact detection node the outlier file as well as the outlier plot\n",
    "- from the motion correction node the motion parameters\n",
    "- from the last node, the detrended functional image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Connect nodes to datasink here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "preproc.connect([(art, datasink, [('outlier_files', 'preproc.@outlier_files'),\n",
    "                                  ('plot_files', 'preproc.@plot_files')]),\n",
    "                 (mcflirt, datasink, [('par_file', 'preproc.@par')]),\n",
    "                 (detrend, datasink, [('detrended_file', 'preproc.@func')]),\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the workflow\n",
    "\n",
    "After adding the datasink folder, let's run the preprocessing workflow again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look now at the output of this datasink folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /output/datasink_handson -I '*js|*json|*pklz|_report|*dot|*html|*txt|*.m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! But we're still not there yet. There are many unnecessary file specifiers that we can get rid off. To do so, we can use `DataSink`'s `substitutions` parameter. For this, we create a list of tuples: on the left we specify the string that we want to replace and on the right, with what we want to replace it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the following substitutions for the DataSink output\n",
    "substitutions = [('asub', 'sub'),\n",
    "                 ('_ses-test_task-fingerfootlips_bold_roi_mcf', ''),\n",
    "                 ('.nii.gz.par', '.par'),\n",
    "                 ]\n",
    "\n",
    "# To get rid of the folder '_subject_id_07' and renaming detrend\n",
    "substitutions += [('_subject_id_%s/detrend' % s,\n",
    "                   '_subject_id_%s/sub-%s_detrend' % (s, s)) for s in subject_list]\n",
    "substitutions += [('_subject_id_%s/' % s, '') for s in subject_list]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the preprocessing workflow again, let's first delete the current output folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delets the current output folder\n",
    "!rm -rf /output/datasink_handson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Runs the preprocessing workflow again, this time with substitutions\n",
    "preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /output/datasink_handson -I '*js|*json|*pklz|_report|*dot|*html|*.m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Preprocessing workflow on 6 right handed subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now let's run the whole workflow for right handed subjects. For this you just need to change the `subject_list` variable and run again the places where this variable is used (i.e. `sf.iterables` and in `DataSink` `substitutions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Update 'subject_list' and its dependencies here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "subject_list = ['02', '03', '04', '07', '08', '09']\n",
    "\n",
    "sf.iterables = [('subject_id', subject_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get rid of the folder '_subject_id_02' and renaming detrend\n",
    "substitutions += [('_subject_id_%s/detrend' % s,\n",
    "                   '_subject_id_%s/sub-%s_detrend' % (s, s)) for s in subject_list]\n",
    "substitutions += [('_subject_id_%s/' % s, '') for s in subject_list]\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the workflow again, this time for all right handed subjects in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Runs the preprocessing workflow again, this time with substitutions\n",
    "preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready for the next section [Hands-on 2: How to create a fMRI analysis workflow](handson_analysis.ipynb)!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
